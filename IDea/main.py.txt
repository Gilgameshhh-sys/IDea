from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import os

# Importamos las librerías del motor de privacidad (Microsoft Presidio)
from presidio_analyzer import AnalyzerEngine
from presidio_analyzer.nlp_engine import NlpEngineProvider
from presidio_anonymizer import AnonymizerEngine

# --- 1. CONFIGURACIÓN DEL MOTOR (El Cerebro) ---
app = FastAPI(title="SecureChat AI Middleware", version="1.0.0")

# Configuración para que Presidio entienda ESPAÑOL
# (Asumimos que el modelo spacy ya se descargó en el Dockerfile)
nlp_config = {
    "nlp_engine_name": "spacy",
    "models": [{"lang_code": "es", "model_name": "es_core_news_lg"}],
}
provider = NlpEngineProvider(nlp_configuration=nlp_config)
analyzer = AnalyzerEngine(nlp_engine=provider.create_engine())
anonymizer = AnonymizerEngine()

# --- 2. EL CONTRATO DE LA API (Modelos de Datos Pydantic) ---

# Lo que el Frontend nos envía (Input)
class SecureChatRequest(BaseModel):
    prompt: str             # El mensaje del usuario (posiblemente con datos sensibles)
    user_id: str = "guest"  # Para logs de auditoría

# Lo que devolvemos (Output) - Aquí está tu valor agregado
class SafetyReport(BaseModel):
    detected_items: List[str]  # Ej: ["PHONE_NUMBER", "PERSON"]
    sanitized_prompt: str      # Lo que realmente vio la IA

class SecureChatResponse(BaseModel):
    ai_response: str           # La respuesta final
    safety_report: SafetyReport # Evidencia de que protegimos al cliente

# --- 3. LOS ENDPOINTS (Tuberías) ---

@app.get("/")
def health_check():
    return {"status": "active", "system": "SecureChat AI Shield"}

@app.post("/chat/secure", response_model=SecureChatResponse)
async def secure_chat(request: SecureChatRequest):
    """
    Recibe un prompt, anonimiza datos sensibles, consulta a la IA y devuelve respuesta.
    """
    try:
        # PASO A: DETECCIÓN (El Detective)
        # Buscamos patrones de PII en español
        analyzer_results = analyzer.analyze(
            text=request.prompt, 
            language='es'
        )

        # PASO B: ANONIMIZACIÓN (El Escudo)
        # Reemplazamos los datos reales por placeholders (Ej: <PERSON>)
        anonymized_result = anonymizer.anonymize(
            text=request.prompt,
            analyzer_results=analyzer_results
        )
        
        prompt_seguro = anonymized_result.text

        # PASO C: LLAMADA A LA IA (El Cerebro)
        # *Nota: Aquí conectaríamos con OpenAI real. 
        # Por ahora, simulamos una respuesta para probar el flujo sin gastar créditos.
        
        # Simulación: La IA responde usando el nombre anonimizado
        ai_simulation = f"Entendido. He procesado la solicitud para {prompt_seguro}. No he visto los datos reales."

        # PASO D: GENERAR REPORTE (Para el Abogado/Gerente)
        detected_types = list(set([res.entity_type for res in analyzer_results]))
        
        return SecureChatResponse(
            ai_response=ai_simulation,
            safety_report=SafetyReport(
                detected_items=detected_types,
                sanitized_prompt=prompt_seguro
            )
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Si ejecutas esto localmente sin Docker:
# uvicorn main:app --reload